{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertinfo\" style=\"margin-top: 0px\">\n",
    "<h1>  Data Preprocessing Tools  - UPDATED </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\" style=\"margin-top: 0px\">\n",
    "<h3> For quick copy and paste I always define feature as column name I'm working on, therefore majority of codes here have word feature in them, which could be replaced with the column name </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'column_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Importing the libraries </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning off jupyter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Creating a snippet </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with list object in values\n",
    "tempData = {\n",
    "    'name' : ['AAA', 'BBB', 'CCC', 'DDD'],\n",
    "    'code' : ['1', '2', '3', '4'],\n",
    "    'result' : ['www@A, AAA, 1','www@B, BBB', 'www@C, 3', 'www@D, EEE, 5'],\n",
    "    'link' : [np.nan,np.nan,np.nan,np.nan],\n",
    "    'validity': [np.nan,np.nan,np.nan,np.nan]    \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(tempData) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Creating a copy </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_origin.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Importing the dataset </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read/Save Data Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Formate  | Read             | Save             |\n",
    "| ------------- |:----------------:| ----------------:|\n",
    "| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n",
    "| json          | `pd.read_json()` |`df.to_json()`    |\n",
    "| excel         | `pd.read_excel()`|`df.to_excel()`   |\n",
    "| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n",
    "| sql           | `pd.read_sql()`  |`df.to_sql()`     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From internet\n",
    "\n",
    "# without headers\n",
    "url = \"https://archive.isc.usci.edu/ml/machine-learningdatabases/autos-imports-85.data\"\n",
    "df=pd.read_csv(url)\n",
    "df.head()\n",
    "\n",
    "# with headers\n",
    "url = \"https://archive.isc.usci.edu/ml/machine-learningdatabases/autos-imports-85.data\"\n",
    "headers = [\"column1\",\"column2\",...,\"column n\"]\n",
    "df = pd.read_csv(url, names = headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From directory\n",
    "df=pd.read_csv(r\"C:\\Users\\giuse\\Desktop\\A-Z\\Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From within same directory\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data base\n",
    "import ibm_db_dbi\n",
    "pconn = ibm_db_dbi.Connection(conn)\n",
    "df = pd.read_sql(‘SELECT *FROM table_name’,pconn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Beautifying </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing index - setting specific column to become an index\n",
    "df.set_index(feature,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing column names\n",
    "df.rename(columns={'oldName1': 'newName1',\n",
    "                   'oldName2': 'newName2'},\n",
    "          inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move a column to the first place \n",
    "y=df.pop(feature)\n",
    "df.insert(0, feature, y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move a column to the last place \n",
    "y=df.pop(feature)\n",
    "df.insert(len(df.columns), feature, y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical columns only\n",
    "df=df.select_dtypes(exclude ='object')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df.drop(['column1', 'column2'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting values by column\n",
    "df = df.sort_values(by=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data info </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "len(df.index)\n",
    "''' or '''\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique rows\n",
    "print('There are {} uniques categories.'.format(len(df[feature].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index number of a column name\n",
    "feature_index=df.columns.get_loc(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of rows and number of unique rows info\n",
    "print('There are {} rows in the original data'.format(df.shape[0]))\n",
    "print('There are {} unique business ID numbers'.format(df[feature].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Duplicates </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding rows that are exactly the same\n",
    "duplicate_rows = df_origin[df.duplicated()]\n",
    "print('There are {} duplicates'.format(duplicate_rows.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows from further analysis\n",
    "df_origin = df_origin.drop_duplicates()\n",
    "print('{} rows left to further analysis'.format(df_origin.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flagging duplicates\n",
    "df['is_duplicate'] = df[['BId Postcode','BI Telephone','BI Website']].duplicated(keep='first')\n",
    "df['reference_column'] = df['BId Postcode'] + df['BI Telephone'] + df['BI Website']\n",
    "original = df[df['is_duplicate']==False].shape[0]\n",
    "duplies = df[df['is_duplicate']==True].shape[0]\n",
    "print('There are {} original and unique Business Id\\'s. Another {} records are duplicates'.format(original,duplies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Missing data </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno\n",
    "\n",
    "# missing values overview\n",
    "missingno.matrix(df_origin,figsize=(16,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_values(data,columns):\n",
    "    missing_vals = {}   \n",
    "    # df_length = len(dataframe)\n",
    "    for column in columns:\n",
    "        #total_column_values = dataframe[column].value_counts().sum()\n",
    "        missing_vals[column] = len(data[column][data[column].isna()])\n",
    "    return missing_vals\n",
    "\n",
    "def missing_values(data):\n",
    "    info = find_missing_values(data,columns = data.columns)\n",
    "    return info\n",
    "\n",
    "def miss_val_info(data, feature):    \n",
    "    missing_val = find_missing_values(data,columns = data.columns)\n",
    "    print(\"The number of missing values in column {} is\".format(feature), + missing_val[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary replacement of nan values with 000\n",
    "miss_val_info(df,feature)\n",
    "temp = '000'\n",
    "df[feature].replace(np.nan,temp,inplace=True)\n",
    "print('Replacement done')\n",
    "miss_val_info(df,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bringing back nan values\n",
    "miss_val_info(df,feature)\n",
    "df[feature] = df[feature].replace(' 000',np.nan)\n",
    "print('Replacement done')\n",
    "miss_val_info(df,feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select cells that contain missing data\n",
    "df.loc[df[feature].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing with mode\n",
    "mode=df[feature].value_counts().idxmax()\n",
    "df[feature].replace(np.nan,mode,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing with mean\n",
    "avg1 = df[feature].astype('float').mean(axis=0)\n",
    "df[feature].replace(np.nan, avg1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "df_choice[feature].replace(np.nan,average,inplace=True) \n",
    "df_choice[feature].fillna(df_choice[feature].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing with mean of a group\n",
    "average = df.groupby('columnn_name_to_groupby').mean()[feature]\n",
    "df.loc[pd.isna(df[feature]),feature] = average[df.loc[pd.isna(df[feature]),'columnn_name_to_groupby']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with Nan values   (if <1% of data is missing dropping those rows is appropriate)\n",
    "df.dropna(subset=[feature], axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True) #reset index because we drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any missing data left - if false then no more missing data\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Filling in missing values from a reference table </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create reference table and reference list - here is just an example\n",
    "def create_ref():\n",
    "    reference_table = df.copy()\n",
    "    column_list = ['BI Business Name','BId Postcode','BI Telephone','BI Website'] \n",
    "    column_list.remove(feature)\n",
    "    reference_table['reference_column'] = reference_table[column_list[0]] + reference_table[column_list[1]] + reference_table[column_list[2]]\n",
    "    df['reference_column'] = df[column_list[0]] + df[column_list[1]] + df[column_list[2]]\n",
    "    reference_list = reference_table['reference_column'].tolist()\n",
    "\n",
    "    # creating reference table and reference list\n",
    "    reference_table = reference_table[[feature,'reference_column']]\n",
    "    reference_table = reference_table.loc[reference_table['reference_column'] == reference_table['reference_column']] # preventing reference being nan\n",
    "    reference_table = reference_table.dropna()\n",
    "    reference_table['flag'] = reference_table.drop(feature, axis=1).duplicated(keep='first')\n",
    "    reference_table = reference_table[reference_table['flag']==False]\n",
    "    reference_table = reference_table.drop('flag', axis=1)\n",
    "    reference_list = reference_table['reference_column'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: call created function above\n",
    "reference_table, reference_list = create_ref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fill in missing values\n",
    "def replace_value(row):\n",
    "    \n",
    "    value_old = row[feature]\n",
    "    if value_old != value_old or value_old == None:\n",
    "        reference_value = row['reference_column']        \n",
    "        if reference_value in reference_list:                \n",
    "            value_new = reference_table[reference_table['reference_column']==reference_value].iloc[0,0]\n",
    "            #print('Missing value was replaced with {}'.format(value_new))\n",
    "            return value_new\n",
    "        else:  \n",
    "            #print(\"Missing value couldn't be replaced\")\n",
    "            return value_old\n",
    "    else:\n",
    "        #print('Not applicable')\n",
    "        return value_old\n",
    "    \n",
    "df[feature]=df.apply(replace_value, axis=1)\n",
    "df = df.drop('reference_column', axis =1)\n",
    "after = len(df[feature][df[feature].isna()])\n",
    "difference = was - after\n",
    "print('{} missing values in feature {} were sucessfully filled in'.format(difference,feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data type </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the data types for each column\n",
    "df_origin.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dtype of the entire column \n",
    "df[feature].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# however object dtype is not exclusive and can contain multiple mixed types so let's check\n",
    "print('Unique cell types:', *df[feature].apply(type).unique(), sep='\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifying data type\n",
    "df[[feature]] = df[[feature]].astype('string')\n",
    "print('Unique cell types:', *df[feature].apply(type).unique(), sep='\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data types for multiple columns\n",
    "df[[\"Col1\", \"Col2\"]] = df[[\"Col1\", \"Col2\"]].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_text(row):\n",
    "    name = row[feature]\n",
    "    name = name.replace('Ltd',\"\")\n",
    "    name = name.replace('Limited',\"\")\n",
    "    name = re.sub(r'[^a-zA-Z0-9]',\"\",name)\n",
    "    name = name.strip()\n",
    "    name = name.upper()\n",
    "    return name   \n",
    "\n",
    "df[feature]=df.apply(unify_text, axis=1)\n",
    "print('Feature {} sucessfully formated'.format(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit conversion\n",
    "df['highway-mpg'] = 235/df['highway-mpg']                         #creates new column\n",
    "df.rename(columns={'highway-mpg':'highway-L/100km'},inplace=True) #permanetly changes column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Regex </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating email address\n",
    "pattern = \"[a-zA-Z0-9]+@[a-zA-Z]+\\.(com|edu|net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all values with special symbols\n",
    "''' special characters like (+ \\ [] ^ ? . * -) need to be escaped with \\ '''\n",
    "pattern = '[/<>=_;:@~#|¬`!\"£$%&()\\-\\*\\.\\?\\^\\[\\]\\+\\\\\\]'\n",
    "def find_symbols(row):\n",
    "    value = row['name']\n",
    "    if re.search(pattern,value) is not None:\n",
    "        print(value)\n",
    "        \n",
    "df['name'] = df.apply(find_symbols, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Binning </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bins (equal size)\n",
    "labels = ['Alone', 'Small_family', 'Medium_family', 'Large_family']\n",
    "bins = [1, 2, 5, 8, np.inf]\n",
    "df_joined['Group_binned'] = pd.cut(df_joined['Group_simple'], bins, right=False, labels=labels)\n",
    "\n",
    "# creating bins (equal frequency)\n",
    "labels = ['Very low','low','medium','high']\n",
    "df_train[feature]=pd.qcut(df_train[feature], q=4,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data analysis </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght analysis\n",
    "length_list = df[feature].astype(str).apply(len).unique()\n",
    "length_list = sorted(length_list)\n",
    "for i in length_list:\n",
    "    print('Sample of values with length of {}:'.format(i))\n",
    "    print(df[df[feature].astype(str).str.len() == i][feature]\n",
    "          .sample(5, replace=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing two values at the same time\n",
    "def double_app(row):\n",
    "    if row['BusinessID'] == 4:\n",
    "        row['BusinessID'] = 666\n",
    "        row['BId Postcode'] = 'SO322'   \n",
    "    return row\n",
    "df = df.apply(double_app,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Measure the run time </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "#####your python script#####\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in seconds: ' + str(executionTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Dummy variables </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align\n",
    "test1_ready, test2_ready = test1_ready.align(test2_ready, join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Using category codes approach\n",
    "\n",
    "# One hot encoding \n",
    "df=pd.get_dummies(df,columns=['Country'],drop_first=False)   \n",
    "or\n",
    "df=pd.get_dummies(df,columns=['Purchased'],drop_first=True)\n",
    "\n",
    "\n",
    "#dfg = df1h.groupby('Country').mean().reset_index()        # Sometimes you might want to group rows by Country and by taking the mean of the frequency of occurrence of each category\n",
    "#dfg.head()\n",
    "\n",
    "# Label encoding\n",
    "df['Purchased'] = df['Purchased'].astype('category')       # This approach requires the category column to be of ‘category’ datatype\n",
    "dfe['Purchased'] = df['Purchased'].cat.codes\n",
    "df=dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding using sklearn approach\n",
    "\n",
    "# One hot Encoding \n",
    "X = df.iloc[:, :-1].values                               # turning independent variables into arrays\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough') # 0 is an index of a column to encode, passthrough means only column 0 is hot encoded, the rest of the columns will be ignored\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "\n",
    "# Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding entire df at once\n",
    "\n",
    "# Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "dfo.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# One hot Encoding \n",
    "train_ready = pd.get_dummies(train)\n",
    "test_ready = pd.get_dummies(test)\n",
    "train_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Feature scaling </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Save the data </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('clean_df.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
