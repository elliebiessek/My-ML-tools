{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37puETfgRzzg"
   },
   "source": [
    "<div class=\"alert alert-info alertinfo\" style=\"margin-top: 0px\">\n",
    "<h1>  Data Preprocessing Tools </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Importing the libraries </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Importing the dataset </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read/Save Data Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Formate  | Read             | Save             |\n",
    "| ------------- |:----------------:| ----------------:|\n",
    "| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n",
    "| json          | `pd.read_json()` |`df.to_json()`    |\n",
    "| excel         | `pd.read_excel()`|`df.to_excel()`   |\n",
    "| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n",
    "| sql           | `pd.read_sql()`  |`df.to_sql()`     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From internet\n",
    "\n",
    "# without headers\n",
    "url = \"https://archive.isc.usci.edu/ml/machine-learningdatabases/autos-imports-85.data\"\n",
    "df=pd.read_csv(url)\n",
    "df.head()\n",
    "\n",
    "# with headers\n",
    "url = \"https://archive.isc.usci.edu/ml/machine-learningdatabases/autos-imports-85.data\"\n",
    "headers = [\"column1\",\"column2\",...,\"column n\"]\n",
    "df = pd.read_csv(url, names = headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From directory\n",
    "df=pd.read_csv(r\"C:\\Users\\giuse\\Desktop\\A-Z\\Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From within same directory\n",
    "df = pd.read_csv('Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data base\n",
    "import ibm_db_dbi\n",
    "pconn = ibm_db_dbi.Connection(conn)\n",
    "df = pd.read_sql(‘SELECT *FROM table_name’,pconn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Beautifying </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing index\n",
    "df.set_index('Colname',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting column as an index\n",
    "df = file.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing column names\n",
    "df.rename(columns={'oldName1': 'newName1',\n",
    "                   'oldName2': 'newName2'},\n",
    "          inplace=True, errors='raise',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning off jupyter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move a column to the first place \n",
    "y=df.pop('column_name')\n",
    "df.insert(0, 'column_name', y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move a column to the last place \n",
    "y=df.pop('column_name')\n",
    "df.insert(len(df.columns), 'column_name', y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numerical columns only\n",
    "df=df.select_dtypes(exclude ='object')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Data info </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique rows\n",
    "print('There are {} uniques categories.'.format(len(df['Category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of a column stored as a feature\n",
    "feature_index=df_test.columns.get_loc(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Missing data </h1>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple!!!\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List column names that contain missing data\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with missing data\n",
    "data_frame=df\n",
    "list_of_columns_with_missing_data=data_frame.columns[data_frame.isnull().any()]\n",
    "data_frame_of_missing_data=data_frame[list_of_columns_with_missing_data]\n",
    "missing_data = data_frame_of_missing_data.isnull()\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"_____________\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select cells that contain missing data\n",
    "df.loc[df['Column'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [],
   "source": [
    "# replacing with mean\n",
    "avg1 = df['Age'].astype('float').mean(axis=0)\n",
    "df['Age'].replace(np.nan, avg1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "df_choice['Age'].replace(np.nan,average,inplace=True) \n",
    "df_choice['Age'].fillna(df_choice['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "hCsz2yCebe1R",
    "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be"
   },
   "outputs": [],
   "source": [
    "# replacing with mode\n",
    "mode=df['Col'].value_counts().idxmax()\n",
    "df['Col'].replace(np.nan,mode,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing with mean of a group\n",
    "average = df.groupby('Title').mean()['Age']\n",
    "df.loc[pd.isna(df['Age']),'Age'] = average[df.loc[pd.isna(df['Age']),'Title']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing from another data frame\n",
    "df_null.fillna(missing_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYrOQ43XcJR3",
    "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44"
   },
   "outputs": [],
   "source": [
    "# dropping rows with Nan values   (if <1% of data is missing dropping those rows is appropriate)\n",
    "df.dropna(subset=['Col'], axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True) #reset index because we drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df = df.drop('Col',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any missing data left - if false then no more missing data\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c93k7ipkSexq"
   },
   "outputs": [],
   "source": [
    "# using imputer\n",
    "\n",
    "# Changing from data frame to arrays\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# using imputer approach\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Correcting Data Format </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the data types for each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types to proper format\n",
    "df[[\"Col\"]] = df[[\"Col\"]].astype(\"float\")\n",
    "df[[\"Col1\", \"Col2\"]] = df[[\"Col1\", \"Col2\"]].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Unit conversion </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit conversion\n",
    "df['highway-mpg'] = 235/df['highway-mpg']                         #creates new column\n",
    "df.rename(columns={'highway-mpg':'highway-L/100km'},inplace=True) #permanetly changes column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Binning </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bins (equal size)\n",
    "labels = ['Alone', 'Small_family', 'Medium_family', 'Large_family']\n",
    "bins = [1, 2, 5, 8, np.inf]\n",
    "df_joined['Group_binned'] = pd.cut(df_joined['Group_simple'], bins, right=False, labels=labels)\n",
    "\n",
    "# creating bins (equal frequency)\n",
    "labels = ['Very low','low','medium','high']\n",
    "df_train[feature]=pd.qcut(df_train[feature], q=4,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Dummy variables </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align\n",
    "test1_ready, test2_ready = test1_ready.align(test2_ready, join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Using category codes approach\n",
    "\n",
    "# One hot encoding \n",
    "df=pd.get_dummies(df,columns=['Country'],drop_first=False)   \n",
    "or\n",
    "df=pd.get_dummies(df,columns=['Purchased'],drop_first=True)\n",
    "\n",
    "\n",
    "#dfg = df1h.groupby('Country').mean().reset_index()        # Sometimes you might want to group rows by Country and by taking the mean of the frequency of occurrence of each category\n",
    "#dfg.head()\n",
    "\n",
    "# Label encoding\n",
    "df['Purchased'] = df['Purchased'].astype('category')       # This approach requires the category column to be of ‘category’ datatype\n",
    "dfe['Purchased'] = df['Purchased'].cat.codes\n",
    "df=dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding using sklearn approach\n",
    "\n",
    "# One hot Encoding \n",
    "X = df.iloc[:, :-1].values                               # turning independent variables into arrays\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough') # 0 is an index of a column to encode, passthrough means only column 0 is hot encoded, the rest of the columns will be ignored\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X)\n",
    "\n",
    "# Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "DWPET8ZdlMnu",
    "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
   },
   "outputs": [],
   "source": [
    "# Encoding entire df at once\n",
    "\n",
    "# Label Encoding \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "dfo.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# One hot Encoding \n",
    "train_ready = pd.get_dummies(train)\n",
    "test_ready = pd.get_dummies(test)\n",
    "train_ready.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Feature scaling </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\" style=\"margin-top: 0px\">\n",
    "<h1> Save to...</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
